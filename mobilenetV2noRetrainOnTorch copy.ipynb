{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgnRyb39Okcp"
      },
      "source": [
        "匯入函式庫和資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pUb-ejkZDcFG",
        "outputId": "30f23e2b-3b08-4d93-db1c-fa4e32a33fd4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
            "  \"class\": algorithms.Blowfish,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg\n",
        "# %matplotlib inline  ← 不支援 PyTorch，註解掉\n",
        "import cv2\n",
        "\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 檢查 GPU\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4zeQ7AnEoYc",
        "outputId": "aefb5a10-7335-4de5-8b47-ca45aefab6d6"
      },
      "outputs": [],
      "source": [
        "INPUT_PATH = \"./data/realwaste-main/RealWaste\"\n",
        "print(os.listdir(INPUT_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ELnDHHQFPD5"
      },
      "outputs": [],
      "source": [
        "glass = Path(INPUT_PATH + '/Glass').glob('*.jpg')\n",
        "metal = Path(INPUT_PATH + '/Metal').glob('*.jpg')\n",
        "foodorga = Path(INPUT_PATH + '/Food Organics').glob('*.jpg')\n",
        "mistrash = Path(INPUT_PATH + '/Miscellaneous Trash').glob('*.jpg')\n",
        "plastic = Path(INPUT_PATH + '/Plastic').glob('*.jpg')\n",
        "paper = Path(INPUT_PATH + '/Paper').glob('*.jpg')\n",
        "textrash = Path(INPUT_PATH + '/Textile Trash').glob('*.jpg')\n",
        "cardboard = Path(INPUT_PATH + '/Cardboard').glob('*.jpg')\n",
        "vegetation = Path(INPUT_PATH + '/Vegetation').glob('*.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNeVC0-hGzhR"
      },
      "outputs": [],
      "source": [
        "galss_data = [(image, 0) for image in glass]\n",
        "metal_data = [(image, 1) for image in metal]\n",
        "foodorga_data = [(image, 2) for image in foodorga]\n",
        "mistrash_data = [(image, 3) for image in mistrash]\n",
        "plastic_data = [(image, 4) for image in plastic]\n",
        "paper_data = [(image, 5) for image in paper]\n",
        "textrash_data = [(image, 6) for image in textrash]\n",
        "cardboard_data = [(image, 7) for image in cardboard]\n",
        "vegetation_data = [(image, 8) for image in vegetation]\n",
        "\n",
        "total_data = galss_data + metal_data + foodorga_data + mistrash_data + plastic_data + paper_data + textrash_data + cardboard_data + vegetation_data\n",
        "total_data = pd.DataFrame(total_data, columns=['image', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dl6qtFpN0E0"
      },
      "outputs": [],
      "source": [
        "train_val_df, test_df = train_test_split(total_data, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAmI4NiWOWTN"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(train_val_df, test_size=1/6, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25OsI74wOzBZ"
      },
      "source": [
        "訓練資料集處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW_LUlDFHWg4"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=1., random_state=100).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "nXzaQhR-Hdr0",
        "outputId": "63976dc9-bc81-4e93-aed0-5c5d83dc5e6c"
      },
      "outputs": [],
      "source": [
        "count_result = train_df['label'].value_counts()\n",
        "print('Total : ', len(train_df))\n",
        "print(count_result)\n",
        "\n",
        "plt.figure(figsize=(24,5))\n",
        "sns.countplot(x = 'label', data =  train_df)\n",
        "plt.title('Number of classes', fontsize=16)\n",
        "plt.xlabel('Class type', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(range(len(count_result.index)),\n",
        "           ['Glass : 0', 'Metal : 1', 'Food Organics : 2', 'Miscellaneous Trash : 3', 'Plastic : 4', 'Paper : 5', 'Textile Trash : 6', 'Cardboard : 7', 'Vegetation : 8'],\n",
        "           fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJWks3zUIok6"
      },
      "outputs": [],
      "source": [
        "class WasteDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = str(self.data.iloc[idx]['image'])\n",
        "        label = self.data.iloc[idx]['label']\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjUDBVfhItpj",
        "outputId": "83b5e8b7-9f03-455a-c12b-b9f71a700fea"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  # 可依需求調整\n",
        "])\n",
        "\n",
        "train_dataset = WasteDataset(train_df, transform=transform)\n",
        "x_train = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "print(\"Total number of training examples:\", len(train_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbJnrNLWS4tg"
      },
      "outputs": [],
      "source": [
        "# 不需 one-hot 編碼，PyTorch 的 CrossEntropyLoss 會自動處理\n",
        "# y_train = tf.keras.utils.to_categorical(y_train,9) ← 可省略\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "P1Mfbw7mTBxQ",
        "outputId": "1ac1e978-29e3-4341-d519-dd9ed66a6fd7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3, 4, figsize=(20,15))\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    image = imread(train_df.image[i])\n",
        "    axi.imshow(image, cmap='bone')\n",
        "    axi.set_title(('Glass' if train_df.label[i] == 0\n",
        "                   else 'Metal' if train_df.label[i] == 1\n",
        "                   else 'Food Organics' if train_df.label[i] == 2\n",
        "                   else 'Miscellaneous Trash' if train_df.label[i] == 3\n",
        "                   else 'Plastic' if train_df.label[i] == 4\n",
        "                   else 'Paper' if train_df.label[i] == 5\n",
        "                   else 'Textile Trash' if train_df.label[i] == 6\n",
        "                   else 'Cardboard' if train_df.label[i] == 7\n",
        "                   else 'Vegetation')\n",
        "                  + '  [size=' + str(image.shape) +']',\n",
        "                  fontsize=14)\n",
        "    axi.set(xticks=[], yticks=[])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crmwWN_SPM0Z"
      },
      "source": [
        "Validation資料集處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-E5c3qQTOAM"
      },
      "outputs": [],
      "source": [
        "val_df = val_df.sample(frac=1., random_state=100).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "fozIGViNPWiZ",
        "outputId": "a29b9b5e-0e8f-49fa-b92f-3338bf815c38"
      },
      "outputs": [],
      "source": [
        "count_result = val_df['label'].value_counts()\n",
        "print('Total : ', len(val_df))\n",
        "print(count_result)\n",
        "\n",
        "plt.figure(figsize=(24,5))\n",
        "sns.countplot(x = 'label', data =  val_df)\n",
        "plt.title('Number of classes', fontsize=16)\n",
        "plt.xlabel('Class type', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(range(len(count_result.index)),\n",
        "           ['Glass : 0', 'Metal : 1', 'Food Organics : 2', 'Miscellaneous Trash : 3', 'Plastic : 4', 'Paper : 5', 'Textile Trash : 6', 'Cardboard : 7', 'Vegetation : 8'],\n",
        "           fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbsEErX_P3TI",
        "outputId": "c18edf1b-eac5-4c49-d7f5-7e463e84c5d9"
      },
      "outputs": [],
      "source": [
        "test_df = test_df.sample(frac=1., random_state=100).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZJ4W9suRxYQ"
      },
      "source": [
        "測試資料集處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "ezB-chc1R8Og",
        "outputId": "1bb3ab65-9758-446b-9b87-dab83f316b51"
      },
      "outputs": [],
      "source": [
        "count_result = test_df['label'].value_counts()\n",
        "print('Total : ', len(test_df))\n",
        "print(count_result)\n",
        "\n",
        "plt.figure(figsize=(24,5))\n",
        "sns.countplot(x = 'label', data =  test_df)\n",
        "plt.title('Number of classes', fontsize=16)\n",
        "plt.xlabel('Class type', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(range(len(count_result.index)),\n",
        "           ['Glass : 0', 'Metal : 1', 'Food Organics : 2', 'Miscellaneous Trash : 3', 'Plastic : 4', 'Paper : 5', 'Textile Trash : 6', 'Cardboard : 7', 'Vegetation : 8'],\n",
        "           fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbq_kHiSPBt",
        "outputId": "405bf514-41b2-422a-ecca-83a7f99a3b36"
      },
      "outputs": [],
      "source": [
        "test_dataset = WasteDataset(test_df, transform=transform)\n",
        "x_test = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Total number of test examples:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doumt8lnPcXy",
        "outputId": "2846c7f7-0edb-4ab0-e783-762fcfb90f6f"
      },
      "outputs": [],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.last_channel, 9)  # 9 類別\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW2a4-IrQ9Gp"
      },
      "outputs": [],
      "source": [
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGcBdtm6Q9mZ"
      },
      "outputs": [],
      "source": [
        "base_learning_rate = 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH9vH_ocRA1B"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=base_learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIGzHmf-RDWh"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "initial_epochs = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCSSTNABRHI5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(initial_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in tqdm(x_train):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    \n",
        "    acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{initial_epochs} - Loss: {running_loss:.4f}, Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAG5R4K2RI0B",
        "outputId": "313ca646-24cf-4cc8-ad94-3c5788b1954e"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in x_test:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print('Test accuracy :', test_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
